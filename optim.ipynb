{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparaméterek optimalizációja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paraméteroptimalizációhoz a Bayesi optimalizációs technikát alkalmazom. Ehhez meg kell hívni a szükséges könyvtárat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the next line if the package is not yet installed in your machine\n",
    "#!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sys\n",
    "sys.path.append('c:\\\\users\\\\ifjto\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages')\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from model import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import *\n",
    "import torch.optim as optim\n",
    "import torch.cuda\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az optimalizálandó paraméterek értékkészletét állítsuk be. Természetesen nem megengedhetőek az óriási értékek, mivel nincs rá elegendő számítási kapacitás - áldozatot kell hoznunk. Ezen persze segíthetünk azzal, hogy több kicsi optimalizálást futtatunk, és megpróbáljuk kitalálni, hogy melyik paraméterértékek túl kicsik vagy nagyok, így szűkítve az optimalizáló értékkészletét. Néhány magyarázat a választott határokhoz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the maximum number of pictures included in each epoch\n",
    "TRAIN_SIZE = 5000\n",
    "\n",
    "pbounds = {'nFeat' : (16, 128),\n",
    "           'dropout' : (0.2, 0.8),\n",
    "           'auto_lr' : (-4.1, -2.5),\n",
    "           'disc_lr' : (-7, -3),\n",
    "           'ratio' : (0.25, 0.8),\n",
    "           'steps_without_disc' : (3, 8),\n",
    "           'decay' : (-9, -3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olvassuk be az adatokat egyszer, hogy ne kelljen minden hiperparaméterkombinációra megint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader, validationloader, discriminator_dataset, disc_loader = get_data(32, TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Készítsünk egy függvényt, amit az optimalizálónk tud használni. A függvény felelőssége legyen, hogy csak elfogadható értékekkel híva a train-t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameters(auto_lr, disc_lr, ratio, dropout, steps_without_disc, decay, nFeat):\n",
    "    global trainloader, testloader, discriminator_dataset, disc_loader\n",
    "    NUM_EPOCH = 20\n",
    "    auto_lr = pow(10, auto_lr)\n",
    "    disc_lr = pow(10, disc_lr)\n",
    "    steps_without_disc = int(round(steps_without_disc))\n",
    "    decay = pow(10, decay)\n",
    "    nFeat = int(round(nFeat))\n",
    "    \n",
    "    # redirecting stdout to avoid disturbing prints\n",
    "    original_out = sys.stdout\n",
    "    sys.stdout = open(\"logs.txt\", \"a\")\n",
    "    \n",
    "    # building network\n",
    "    autoencoder = Autoencoder(nFeat)\n",
    "    auto_optimizer = optim.Adam(autoencoder.parameters(), lr=auto_lr)\n",
    "    auto_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(auto_optimizer, NUM_EPOCH)\n",
    "    \n",
    "    discriminator = Discriminator(dropout)\n",
    "    disc_optimizer = optim.Adam(discriminator.parameters(), lr=disc_lr)\n",
    "    disc_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(disc_optimizer, NUM_EPOCH)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        discriminator = discriminator.cuda()\n",
    "    \n",
    "    # training network\n",
    "    train(autoencoder, discriminator, trainloader, discriminator_dataset, disc_loader, NUM_EPOCH, ratio=ratio, \n",
    "          steps_without_disc=steps_without_disc, TRAIN_SIZE=TRAIN_SIZE, AUTO_LR=auto_lr, DISC_LR=disc_lr, wd=decay)\n",
    "    \n",
    "    r1, r2 = get_result(autoencoder, testloader)\n",
    "    result = r1*0.1 + r2*0.9\n",
    "    \n",
    "    # saving results\n",
    "    sys.stdout = open(\"results.csv\", \"a\")\n",
    "    print(str(result)+\",\"+str(r1)+\",\"+str(r2)+\",\"+str(math.log(auto_lr, 10))+\",\"+str(math.log(disc_lr, 10))+\",\"+\n",
    "          str(ratio)+\",\"+str(dropout)+\",\"+str(steps_without_disc)+\",\"+str(math.log(decay, 10))+\",\"+str(nFeat))\n",
    "    # resetting the stdout\n",
    "    sys.stdout = original_out\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimalizáljunk. A jó eredményhez kezdjük néhány random lépéssel a próbálkozást."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "optimizer = BayesianOptimization(\n",
    "    f=test_parameters,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=25,\n",
    "    n_iter=75,\n",
    ")\n",
    "\n",
    "print(optimizer.max)\n",
    "print('Finished after ', round(time.time() - start_time), \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az értékkészletek csökkentéséhez rajzoljuk ki az eredmények függését az egyes hiperparaméterektől. Természetesen elképzelhető sokkal komplexebb összefüggés is a hiperparaméterek között, azonban ennyi paraméter együttes vizualizációja óriási kihívás lenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "#reading file\n",
    "lines = []\n",
    "with open(\"results.csv\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "#preparing input\n",
    "header = lines[0][:-1].split(\",\")\n",
    "del(lines[0])\n",
    "\n",
    "columns = [ [] for i in range(len(header)) ]\n",
    "for i in range(len(lines)):\n",
    "    for k in range(len(header)):\n",
    "        columns[k].append( float(lines[i][:-1].split(\",\")[k]) )\n",
    "\n",
    "for i in range(3, len(header)):\n",
    "    f = plt.figure(figsize=(7, 4))\n",
    "    plt.ylabel('reality_score')\n",
    "    plt.xlabel(header[i])\n",
    "    plt.scatter(columns[i], columns[0], s=50, alpha=0.25, edgecolors='none')\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
